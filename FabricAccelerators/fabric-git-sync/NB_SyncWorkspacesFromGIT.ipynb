{"cells":[{"cell_type":"markdown","source":["# Sync Git-Enabled Workspaces from a Remote Repository\n","\n","This notebook provides an automated solution to find and update Fabric workspaces that are integrated with Git. \n","\n","### Functionality\n","1.  **Finds Workspaces**: Scans the tenant for all Git-enabled workspaces on a dedicated capacity.\n","2.  **Checks Git Status**: Determines if each workspace is behind the remote `main` branch.\n","3.  **Updates Safely**: If a workspace is behind **and** has no local changes, it is automatically updated.\n","4.  **Reports Conflicts**: Returns a final DataFrame listing workspaces with potential merge conflicts that require manual review.\n","\n","For full documentation, please see the `README.md` file in the GitHub repository."],"metadata":{},"id":"914a8251-dc7b-4059-9a85-bd74068d584f"},{"cell_type":"markdown","source":["#### 0. Check and Install Required Libraries\n","This section checks if the `semantic-link-labs` library is installed.\n","If not, it will be installed automatically. You can opt for configuring a workspace environment with the package installed to improve performance and maintenance instead."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7c76c3d3-8556-4d1c-af87-3a58c48ec1ce"},{"cell_type":"code","source":["import importlib\n","import sys\n","\n","try:\n","    importlib.import_module('sempy_labs')\n","    #print(\"semantic-link-labs is already installed.\")\n","except ImportError:\n","    print(\"semantic-link-labs not found. Installing now...\")\n","    # Using pip to install the package. The -U flag ensures the latest version is installed.\n","    if 'ipykernel' in sys.modules:\n","        get_ipython().system('pip install -U semantic-link-labs')\n","    else:\n","        import subprocess\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"semantic-link-labs\"])\n","    print(\"Installation complete.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b5429478-e4db-4315-b0cf-96e4f3d220dd"},{"cell_type":"markdown","source":["### 1. Import Packages and Libraries\n","\n","The following packages are required for the notebook to function. The key library is `sempy_labs`, which provides the necessary functions to interact with Fabric workspaces and their Git status."],"metadata":{},"id":"a15bd074-3134-4756-a9db-9e00ecc4a123"},{"cell_type":"code","source":["import os\n","import sempy_labs\n","import pandas as pd\n","import requests"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f263e3d7-9688-4ad9-968f-940dc1cbb6b4"},{"cell_type":"markdown","source":["### 2. Define Core Functions\n","\n","These functions handle the logic for fetching Git status and updating workspaces."],"metadata":{},"id":"1378d6dc-a37c-4dc5-b557-504332df0e45"},{"cell_type":"code","source":["import pandas as pd\n","# Make sure sempy_labs is imported and configured\n","\n","def get_git_status_for_workspaces(df_filtered):\n","    \"\"\"\n","    Retrieves the Git status for a list of workspaces and returns it as a DataFrame.\n","    \n","    Args:\n","        df_filtered (pd.DataFrame): A DataFrame containing a 'Name' column with workspace names.\n","        \n","    Returns:\n","        tuple[pd.DataFrame, pd.DataFrame]: A tuple containing two DataFrames:\n","                                           1. A DataFrame with the detailed Git status for each item in the workspaces.\n","                                           2. A DataFrame listing workspaces where the Git status could not be retrieved.\n","    \"\"\"\n","    git_status_dfs = []  # A list to hold the DataFrames from each workspace\n","    no_git_status_list = []\n","    \n","    for workspace_name in df_filtered[\"Name\"]:\n","        try:\n","            # The function returns a DataFrame directly.\n","            git_status_df = sempy_labs.get_git_status(workspace=workspace_name)\n","            \n","            # Check if the returned DataFrame is empty.\n","            if git_status_df.empty:\n","                continue\n","            \n","            # Add the workspace name and append the whole DataFrame.\n","            git_status_df['Workspace Name'] = workspace_name\n","            git_status_dfs.append(git_status_df)\n","        \n","        except Exception as e:\n","            # Silently collect workspaces where status could not be retrieved.\n","            error_message = str(e)\n","            no_git_status_list.append({'Workspace Name': workspace_name, 'Error': error_message[:200]})\n","\n","    # Concatenate all the collected DataFrames into a single one.\n","    final_git_status_df = pd.concat(git_status_dfs, ignore_index=True) if git_status_dfs else pd.DataFrame()\n","    \n","    total_workspaces = len(df_filtered[\"Name\"])\n","    workspaces_with_status = len(git_status_dfs)\n","\n","    additional_message = \"\"\n","    if workspaces_with_status == 0 and no_git_status_list:\n","        additional_message = \"\\nCheck 'no_git_status_df' for errors. This often means workspaces are not configured with Git.\"\n","\n","    print(f\"Found Git status for {workspaces_with_status} out of {total_workspaces} total workspaces.{additional_message}\")\n","    \n","    return final_git_status_df, pd.DataFrame(no_git_status_list)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6bb89ac9-270b-4cc1-9b0d-eabee9c64756"},{"cell_type":"code","source":["def update_clean_workspaces_from_git(git_status_df):\n","    \"\"\"\n","    Updates workspaces that have no local changes and separates those that do.\n","\n","    Args:\n","        git_status_df (pd.DataFrame): DataFrame from get_git_status_for_workspaces().\n","    \n","    Returns:\n","        pd.DataFrame: A DataFrame of workspaces with local changes that require manual review.\n","    \"\"\"\n","    if git_status_df.empty:\n","        print(\"No workspaces with Git status information were found to process.\")\n","        return pd.DataFrame()\n","        \n","    # Group by workspace to check the status of each one individually\n","    grouped = git_status_df.groupby('Workspace Name')\n","    \n","    # Identify workspaces that have local changes (potential conflicts)\n","    workspaces_with_local_changes = grouped.filter(\n","        lambda group: not pd.isna(group['Workspace Change']).all()\n","    )\n","    \n","    # Identify workspaces with no local changes (safe to update)\n","    clean_workspaces_to_update = grouped.filter(\n","        lambda group: pd.isna(group['Workspace Change']).all()\n","    )\n","    \n","    # Get a unique row for each clean workspace to use for the update API call\n","    unique_clean_workspaces = clean_workspaces_to_update.drop_duplicates(subset=['Workspace Name'])\n","\n","    print(f\"Found {len(unique_clean_workspaces)} workspaces that are safe to update automatically.\")\n","    for _, row in unique_clean_workspaces.iterrows():\n","        try:\n","            # These parameters are safe because we've already filtered out workspaces with local changes\n","            sempy_labs.update_from_git(\n","                workspace=row['Workspace Name'],\n","                remote_commit_hash=row['Remote Commit Hash'],\n","                conflict_resolution_policy=\"PreferRemote\",\n","                workspace_head=row['Workspace Head'],\n","                allow_override=True\n","            )\n","            print(f\"✅ Successfully updated workspace: {row['Workspace Name']}\")\n","        except Exception as e:\n","            print(f\"❌ Failed to update workspace '{row['Workspace Name']}': {str(e)[:120]}\")\n","\n","    return workspaces_with_local_changes"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7e8132cf-67ff-4011-bbb4-c78805e72c26"},{"cell_type":"markdown","source":["### 3. Execute Synchronization\n","\n","The following cells execute the process. It starts by listing all workspaces, filtering them, checking their Git status, and finally applying updates where it is safe to do so."],"metadata":{},"id":"0d625646-329e-464e-aa17-c4d2e49e9458"},{"cell_type":"code","source":["# Step 1: Get a list of all workspaces in the tenant.\n","# This requires tenant admin permissions for the user/principal running the notebook.\n","print(\"Fetching all workspaces in the tenant...\")\n","all_workspaces_df = sempy_labs.admin.list_workspaces()\n","print(f\"Found {len(all_workspaces_df)} total workspaces.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7aa3f0e9-2340-4e3e-a12a-31c69e77ad42"},{"cell_type":"code","source":["# Step 2: Filter for standard workspaces on a dedicated capacity.\n","# This avoids personal workspaces and those not assigned to a capacity.\n","print(\"\\nFinding workspaces on a dedicated capacity...\")\n","filtered_workspaces_df = all_workspaces_df[(all_workspaces_df['Capacity Id'].notna()) & (all_workspaces_df['Type'] == \"Workspace\")]\n","print(f\"Found {len(filtered_workspaces_df)} workspaces on a dedicated capacity.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"18b0bb11-860b-413c-a5a1-cd1de628ac34"},{"cell_type":"code","source":["# Step 3: Retrieve the Git status for the filtered workspaces.\n","print(\"\\nChecking Git status for each workspace...\")\n","git_status_df, no_git_status_df = get_git_status_for_workspaces(filtered_workspaces_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f4ef2214-8ee3-4ae8-b48f-29ca8aefb55c"},{"cell_type":"code","source":["# Step 4: Run the update function for all eligible workspaces.\n","print(\"\\nStarting update process for workspaces with no local changes...\")\n","non_null_workspaces_df = update_clean_workspaces_from_git(git_status_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1d138a7f-f3d4-489a-9718-2b4afcb88706"},{"cell_type":"markdown","source":["### 4. Review Workspaces Requiring Manual Sync\n","\n","The following workspaces have changes made in PBI / Fabric and were **not** automatically updated. Please review each workspace in the Fabric UI to commit changes or resolve conflicts manually."],"metadata":{},"id":"76731e68-1915-4219-94a7-2f7d9e41436a"},{"cell_type":"code","source":["if not non_null_workspaces_df.empty:\n","    print(f\"\\nFound {len(non_null_workspaces_df['Workspace Name'].unique())} workspaces that require manual review:\")\n","    display(non_null_workspaces_df)\n","else:\n","    print(\"\\nAll Git-enabled workspaces are at or ahead of git branch. No manual review needed.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"842db96f-5a09-4ff7-a57c-aa25fb1d3610"}],"metadata":{"kernelspec":{"display_name":"Synapse PySpark","language":"python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"kernel_info":{"name":"synapse_pyspark"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"environment":{"environmentId":"f0917d7d-ef4e-4de9-ba24-5356e2938adb","workspaceId":"33ae0122-bb81-4d92-9ab5-91e61f9cc4e7"}}},"nbformat":4,"nbformat_minor":5}