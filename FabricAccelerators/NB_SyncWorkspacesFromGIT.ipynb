{"cells":[{"cell_type":"markdown","source":["# Sync Git-Enabled Workspaces from a Remote Repository\n","\n","This notebook provides an automated solution to find and update Fabric workspaces that are integrated with Git. \n","\n","### Functionality\n","1.  **Finds Workspaces**: Scans the tenant for all Git-enabled workspaces on a dedicated capacity.\n","2.  **Checks Git Status**: Determines if each workspace is behind the remote `main` branch.\n","3.  **Updates Safely**: If a workspace is behind **and** has no local changes, it is automatically updated.\n","4.  **Reports Conflicts**: Returns a final DataFrame listing workspaces with potential merge conflicts that require manual review.\n","\n","For full documentation, please see the `README.md` file in the GitHub repository."],"metadata":{},"id":"914a8251-dc7b-4059-9a85-bd74068d584f"},{"cell_type":"markdown","source":["#### 0. Check and Install Required Libraries\n","This section checks if the `semantic-link-labs` library is installed.\n","If not, it will be installed automatically. You can opt for configuring a workspace environment with the package installed to improve performance and maintenance instead."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7c76c3d3-8556-4d1c-af87-3a58c48ec1ce"},{"cell_type":"code","source":["import importlib\n","import sys\n","\n","try:\n","    importlib.import_module('sempy_labs')\n","    #print(\"semantic-link-labs is already installed.\")\n","except ImportError:\n","    print(\"semantic-link-labs not found. Installing now...\")\n","    # Using pip to install the package. The -U flag ensures the latest version is installed.\n","    if 'ipykernel' in sys.modules:\n","        get_ipython().system('pip install -U semantic-link-labs')\n","    else:\n","        import subprocess\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"semantic-link-labs\"])\n","    print(\"Installation complete.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":[],"state":"session_error","livy_statement_state":null,"session_id":null,"normalized_state":"session_error","queued_time":"2025-07-10T08:57:54.723345Z","session_start_time":"2025-07-10T08:57:54.7243097Z","execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"0af9b8b5-6b27-4293-aed6-54c4e16ec19d"},"text/plain":"StatementMeta(, , -1, SessionError, , SessionError)"},"metadata":{}},{"output_type":"error","ename":"InvalidHttpRequestToLivy","evalue":"[TooManyRequestsForCapacity] This spark job can't be run because you have hit a spark compute or API rate limit. To run this spark job, cancel an active Spark job through the Monitoring hub, choose a larger capacity SKU, or try again later. HTTP status code: 430 {Learn more} HTTP status code: 430.","traceback":["InvalidHttpRequestToLivy: [TooManyRequestsForCapacity] This spark job can't be run because you have hit a spark compute or API rate limit. To run this spark job, cancel an active Spark job through the Monitoring hub, choose a larger capacity SKU, or try again later. HTTP status code: 430 {Learn more} HTTP status code: 430."]}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b5429478-e4db-4315-b0cf-96e4f3d220dd"},{"cell_type":"markdown","source":["### 1. Import Packages and Libraries\n","\n","The following packages are required for the notebook to function. The key library is `sempy_labs`, which provides the necessary functions to interact with Fabric workspaces and their Git status."],"metadata":{},"id":"a15bd074-3134-4756-a9db-9e00ecc4a123"},{"cell_type":"code","source":["import os\n","import sempy_labs\n","import pandas as pd\n","import requests"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"ee7fd5c4-669a-43d0-b068-276a3e0a82b0","normalized_state":"finished","queued_time":"2025-07-10T09:03:50.9665384Z","session_start_time":"2025-07-10T09:03:50.9682177Z","execution_start_time":"2025-07-10T09:05:02.692054Z","execution_finish_time":"2025-07-10T09:05:19.8441959Z","parent_msg_id":"8931daf9-3e54-45ef-9b4a-7f5672c6c1a0"},"text/plain":"StatementMeta(, ee7fd5c4-669a-43d0-b068-276a3e0a82b0, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f263e3d7-9688-4ad9-968f-940dc1cbb6b4"},{"cell_type":"markdown","source":["### 2. Define Core Functions\n","\n","These functions handle the logic for fetching Git status and updating workspaces."],"metadata":{},"id":"1378d6dc-a37c-4dc5-b557-504332df0e45"},{"cell_type":"code","source":["def get_git_status_for_workspaces(df_filtered):\n","    \"\"\"\n","    Retrieves the Git status for a list of workspaces and returns it as a DataFrame.\n","    \n","    Args:\n","        df_filtered (pd.DataFrame): A DataFrame containing a 'Name' column with workspace names.\n","        \n","    Returns:\n","        tuple[pd.DataFrame, pd.DataFrame]: A tuple containing two DataFrames:\n","                                           1. A DataFrame with the detailed Git status for each item in the workspaces.\n","                                           2. A DataFrame listing workspaces where the Git status could not be retrieved.\n","    \"\"\"\n","    git_status_list = []\n","    no_git_status_list = []\n","    for workspace_name in df_filtered[\"Name\"]:\n","        try:\n","            git_status = sempy_labs.get_git_status(workspace=workspace_name)\n","            \n","            # The API returns a dictionary of lists; unpack it into a list of dictionaries (a tabular format).\n","            if not git_status or not any(git_status.values()):\n","                continue\n","            \n","            max_length = max(len(v) for v in git_status.values())\n","            for i in range(max_length):\n","                # Create a dictionary for each item's status and append it to the list\n","                status_record = {'Workspace Name': workspace_name}\n","                for key, value_list in git_status.items():\n","                    status_record[key] = value_list[i] if i < len(value_list) else None\n","                git_status_list.append(status_record)\n","        \n","        except Exception as e:\n","            # Silently collect workspaces where status could not be retrieved.\n","            error_message = str(e)\n","            no_git_status_list.append({'Workspace Name': workspace_name, 'Error': error_message[:200]})\n","\n","    additional_message = \"\"\n","    if not git_status_list: # len(no_git_status_list) == len(git_status_list) + len(no_git_status_list):\n","        additional_message = \"\\nCheck 'no_git_status_df' to see errors - usualy its an indication that you have workspaces that have not had git configured\"\n","\n","    # Use the variable in the f-string\n","    print(f\"found {len(git_status_list)} workspaces with valid git status out of {len(git_status_list) + len(no_git_status_list)} total workspaces on a dedicated capacity{additional_message}\")\n","    return pd.DataFrame(git_status_list), pd.DataFrame(no_git_status_list)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":20,"statement_ids":[20],"state":"finished","livy_statement_state":"available","session_id":"ee7fd5c4-669a-43d0-b068-276a3e0a82b0","normalized_state":"finished","queued_time":"2025-07-10T09:23:12.5564367Z","session_start_time":null,"execution_start_time":"2025-07-10T09:23:12.5577958Z","execution_finish_time":"2025-07-10T09:23:12.878763Z","parent_msg_id":"c94f5e2f-dc58-436f-ba01-bdfab4056734"},"text/plain":"StatementMeta(, ee7fd5c4-669a-43d0-b068-276a3e0a82b0, 20, Finished, Available, Finished)"},"metadata":{}}],"execution_count":16,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6bb89ac9-270b-4cc1-9b0d-eabee9c64756"},{"cell_type":"code","source":["def update_clean_workspaces_from_git(git_status_df):\n","    \"\"\"\n","    Updates workspaces that have no local changes and separates those that do.\n","\n","    Args:\n","        git_status_df (pd.DataFrame): DataFrame from get_git_status_for_workspaces().\n","    \n","    Returns:\n","        pd.DataFrame: A DataFrame of workspaces with local changes that require manual review.\n","    \"\"\"\n","    if git_status_df.empty:\n","        print(\"No workspaces with Git status information were found to process.\")\n","        return pd.DataFrame()\n","        \n","    # Group by workspace to check the status of each one individually\n","    grouped = git_status_df.groupby('Workspace Name')\n","    \n","    # Identify workspaces that have local changes (potential conflicts)\n","    workspaces_with_local_changes = grouped.filter(\n","        lambda group: not pd.isna(group['Workspace Change']).all()\n","    )\n","    \n","    # Identify workspaces with no local changes (safe to update)\n","    clean_workspaces_to_update = grouped.filter(\n","        lambda group: pd.isna(group['Workspace Change']).all()\n","    )\n","    \n","    # Get a unique row for each clean workspace to use for the update API call\n","    unique_clean_workspaces = clean_workspaces_to_update.drop_duplicates(subset=['Workspace Name'])\n","\n","    print(f\"Found {len(unique_clean_workspaces)} workspaces that are safe to update automatically.\")\n","    for _, row in unique_clean_workspaces.iterrows():\n","        try:\n","            # These parameters are safe because we've already filtered out workspaces with local changes\n","            sempy_labs.update_from_git(\n","                workspace=row['Workspace Name'],\n","                remote_commit_hash=row['Remote Commit Hash'],\n","                conflict_resolution_policy=\"PreferRemote\",\n","                workspace_head=row['Workspace Head'],\n","                allow_override=True\n","            )\n","            print(f\"✅ Successfully updated workspace: {row['Workspace Name']}\")\n","        except Exception as e:\n","            print(f\"❌ Failed to update workspace '{row['Workspace Name']}': {str(e)[:120]}\")\n","\n","    return workspaces_with_local_changes"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"ee7fd5c4-669a-43d0-b068-276a3e0a82b0","normalized_state":"finished","queued_time":"2025-07-10T09:05:25.9000045Z","session_start_time":null,"execution_start_time":"2025-07-10T09:05:25.9012646Z","execution_finish_time":"2025-07-10T09:05:26.1383517Z","parent_msg_id":"f22ed771-87bc-4e5c-86b3-8422cb5a956c"},"text/plain":"StatementMeta(, ee7fd5c4-669a-43d0-b068-276a3e0a82b0, 7, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7e8132cf-67ff-4011-bbb4-c78805e72c26"},{"cell_type":"markdown","source":["### 3. Execute Synchronization\n","\n","The following cells execute the process. It starts by listing all workspaces, filtering them, checking their Git status, and finally applying updates where it is safe to do so."],"metadata":{},"id":"0d625646-329e-464e-aa17-c4d2e49e9458"},{"cell_type":"code","source":["# Step 1: Get a list of all workspaces in the tenant.\n","# This requires tenant admin permissions for the user/principal running the notebook.\n","print(\"Fetching all workspaces in the tenant...\")\n","all_workspaces_df = sempy_labs.admin.list_workspaces()\n","print(f\"Found {len(all_workspaces_df)} total workspaces.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"ee7fd5c4-669a-43d0-b068-276a3e0a82b0","normalized_state":"finished","queued_time":"2025-07-10T09:05:27.6079331Z","session_start_time":null,"execution_start_time":"2025-07-10T09:05:27.6090109Z","execution_finish_time":"2025-07-10T09:05:29.1112305Z","parent_msg_id":"006a9ce7-6b72-41f4-a024-cb9b68500cb9"},"text/plain":"StatementMeta(, ee7fd5c4-669a-43d0-b068-276a3e0a82b0, 8, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fetching all workspaces in the tenant...\nFound 342 total workspaces.\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7aa3f0e9-2340-4e3e-a12a-31c69e77ad42"},{"cell_type":"code","source":["# Step 2: Filter for standard workspaces on a dedicated capacity.\n","# This avoids personal workspaces and those not assigned to a capacity.\n","print(\"\\nFinding workspaces on a dedicated capacity...\")\n","filtered_workspaces_df = all_workspaces_df[(all_workspaces_df['Capacity Id'].notna()) & (all_workspaces_df['Type'] == \"Workspace\")]\n","print(f\"Found {len(filtered_workspaces_df)} workspaces on a dedicated capacity.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"ee7fd5c4-669a-43d0-b068-276a3e0a82b0","normalized_state":"finished","queued_time":"2025-07-10T09:05:28.2409474Z","session_start_time":null,"execution_start_time":"2025-07-10T09:05:29.1134926Z","execution_finish_time":"2025-07-10T09:05:29.3831481Z","parent_msg_id":"f0e160d8-f87c-4427-98ab-fe9103f780e3"},"text/plain":"StatementMeta(, ee7fd5c4-669a-43d0-b068-276a3e0a82b0, 9, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Filtered down to 16 workspaces on a dedicated capacity.\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"18b0bb11-860b-413c-a5a1-cd1de628ac34"},{"cell_type":"code","source":["# Step 3: Retrieve the Git status for the filtered workspaces.\n","print(\"\\nChecking Git status for each workspace...\")\n","git_status_df, no_git_status_df = get_git_status_for_workspaces(filtered_workspaces_df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":21,"statement_ids":[21],"state":"finished","livy_statement_state":"available","session_id":"ee7fd5c4-669a-43d0-b068-276a3e0a82b0","normalized_state":"finished","queued_time":"2025-07-10T09:23:15.8901245Z","session_start_time":null,"execution_start_time":"2025-07-10T09:23:15.8913498Z","execution_finish_time":"2025-07-10T09:23:33.9428955Z","parent_msg_id":"3b602414-5d40-4055-9085-01b289c7f9c4"},"text/plain":"StatementMeta(, ee7fd5c4-669a-43d0-b068-276a3e0a82b0, 21, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\nChecking Git status for each workspace...\nfound 0 workspaces with valid git status out of 16 total workspaces on a dedicated capacity\nCheck 'no_git_status_df' to see errors - usualy its an indication that you have workspaces that have not had git configured\n"]}],"execution_count":17,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f4ef2214-8ee3-4ae8-b48f-29ca8aefb55c"},{"cell_type":"code","source":["# Step 4: Run the update function for all eligible workspaces.\n","print(\"\\nStarting update process for workspaces with no local changes...\")\n","non_null_workspaces_df = update_clean_workspaces_from_git(git_status_df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"afbe86e4-1e5c-4515-8bf2-633688f2688a","normalized_state":"finished","queued_time":"2025-07-10T08:13:32.8796975Z","session_start_time":null,"execution_start_time":"2025-07-10T08:16:35.4810325Z","execution_finish_time":"2025-07-10T08:16:35.7082139Z","parent_msg_id":"9ff1bf32-5b3b-4d22-8574-2ca61b1d87a8"},"text/plain":"StatementMeta(, afbe86e4-1e5c-4515-8bf2-633688f2688a, 11, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\nStarting update process for workspaces with no local changes...\nNo workspaces with Git status information were found to process.\n"]}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1d138a7f-f3d4-489a-9718-2b4afcb88706"},{"cell_type":"markdown","source":["### 4. Review Workspaces Requiring Manual Sync\n","\n","The following workspaces have changes made in PBI / Fabric and were **not** automatically updated. Please review each workspace in the Fabric UI to commit changes or resolve conflicts manually."],"metadata":{},"id":"76731e68-1915-4219-94a7-2f7d9e41436a"},{"cell_type":"code","source":["if not non_null_workspaces_df.empty:\n","    print(f\"\\nFound {len(non_null_workspaces_df['Workspace Name'].unique())} workspaces that require manual review:\")\n","    display(non_null_workspaces_df)\n","else:\n","    print(\"\\nAll Git-enabled workspaces are at or ahead of git branch. No manual review needed.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"afbe86e4-1e5c-4515-8bf2-633688f2688a","normalized_state":"finished","queued_time":"2025-07-10T08:13:34.7158082Z","session_start_time":null,"execution_start_time":"2025-07-10T08:16:35.7101011Z","execution_finish_time":"2025-07-10T08:16:35.9384594Z","parent_msg_id":"f7e8c7ca-3caf-43b7-92f4-e1a4171c9112"},"text/plain":"StatementMeta(, afbe86e4-1e5c-4515-8bf2-633688f2688a, 12, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\nAll Git-enabled workspaces are in sync. No manual review needed.\n"]}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"842db96f-5a09-4ff7-a57c-aa25fb1d3610"}],"metadata":{"kernelspec":{"display_name":"Synapse PySpark","language":"python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"kernel_info":{"name":"synapse_pyspark"},"dependencies":{"environment":{"environmentId":"f0917d7d-ef4e-4de9-ba24-5356e2938adb","workspaceId":"33ae0122-bb81-4d92-9ab5-91e61f9cc4e7"}}},"nbformat":4,"nbformat_minor":5}